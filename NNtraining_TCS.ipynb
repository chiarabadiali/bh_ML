{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import progressbar\n",
    "import os\n",
    "from os import listdir\n",
    "from matplotlib import pyplot as plt\n",
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Dependencies\n",
    "\n",
    "\n",
    "Dependences are fundamental to record the computational environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.9\n",
      "IPython version      : 7.26.0\n",
      "\n",
      "pandas    : 1.2.3\n",
      "keras     : 2.4.3\n",
      "numpy     : None\n",
      "math      : unknown\n",
      "tensorflow: 2.5.0\n",
      "matplotlib: 3.4.2\n",
      "h5py      : 3.1.0\n",
      "imblearn  : 0.8.1\n",
      "\n",
      "Compiler    : Clang 12.0.0 (clang-1200.0.32.29)\n",
      "OS          : Darwin\n",
      "Release     : 21.4.0\n",
      "Machine     : x86_64\n",
      "Processor   : i386\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n",
      " \n",
      "Last updated: Thu Jul 14 2022 11:15:17WEST\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "\n",
    "# python, ipython, packages, and machine characteristics\n",
    "%watermark -v -m -p pandas,keras,numpy,math,tensorflow,matplotlib,h5py,imblearn\n",
    "\n",
    "# date\n",
    "print (\" \")\n",
    "%watermark -u -n -t -z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(class_data): \n",
    "    np.random.shuffle(class_data)\n",
    "    iX = np.arange(class_data.shape[0])\n",
    "    np.random.shuffle(iX)\n",
    "    class_data = class_data[iX]\n",
    "    #change this value if you want to change the normalization factor of the TCS (to have a better training)\n",
    "    #but please keep in mind that if you use the sigmoid as the last layer you have to have values between 0 and 1\n",
    "    #to predict!\n",
    "    norm = 1e26\n",
    "    class_data[:,2] *= norm\n",
    "    y = class_data[:,2]\n",
    "    x = class_data[:,0:2]\n",
    "    #the number of columns you take it's going to change depending on the case you have\n",
    "    train_split = 0.85\n",
    "    train_limit = int(len(y)*train_split)\n",
    "    print(\"Training sample of: {0} \\nValuation sample: {1}\".format(train_limit, len(y)-train_limit))\n",
    "    x_train = x[:train_limit]\n",
    "    x_val = x[train_limit:]\n",
    "    y_train = y[:train_limit]\n",
    "    y_val = y[train_limit:]\n",
    "    if np.isnan(np.min(y)) == False:\n",
    "        return x_train, y_train, x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histo(x, y, bins,logscale):\n",
    "    y = np.array(y)\n",
    "    plt.hist(y, bins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Probability')\n",
    "    if logscale == 1:\n",
    "        plt.yscale('log')\n",
    "    plt.title('Trained on ($p_e$, $p_{\\gamma}$, $\\omega_e$, $\\omega_{\\gamma}$, n)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loaddata(name):\n",
    "     return np.loadtxt(name, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data2(class_data, nbins, ratio):\n",
    "    y = class_data[:,2]\n",
    "    n, edges, _ = plt.hist(y, nbins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "    n_max = int(n.max())*ratio\n",
    "    data = []\n",
    "    bar = progressbar.ProgressBar(maxval=len(class_data), \n",
    "                              widgets=[progressbar.Bar('=', '[', ']'), ' ', \n",
    "                                       progressbar.Percentage(), \n",
    "                                       \" of {0}\".format(len(class_data))])\n",
    "    bar.start()\n",
    "    cow = 0\n",
    "    for k, class_ in enumerate(class_data):\n",
    "        for i in range(len(n)):\n",
    "            edges_min = edges[i]\n",
    "            edges_max = edges[i+1]\n",
    "            if class_[0] > edges_min and class_[0] < edges_max:\n",
    "                if int(n[i]/n_max) > 1 :\n",
    "                    step = int(n[i]/n_max)\n",
    "                    if cow%step==0:\n",
    "                        data.append(class_)\n",
    "                    cow +=1\n",
    "                else:\n",
    "                    for j in range(int(n_max/(n[i]))):\n",
    "                        data.append(class_)\n",
    "        bar.update(k+1)\n",
    "            \n",
    "    bar.finish()\n",
    "\n",
    "    #plt.hist(data, nbins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "    \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(class_data, nbins):\n",
    "    y = class_data[:,2]\n",
    "    n, edges, _ = plt.hist(y, nbins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "    n_max = int(n.max())\n",
    "    data = []\n",
    "    bar = progressbar.ProgressBar(maxval=len(class_data), \n",
    "                              widgets=[progressbar.Bar('=', '[', ']'), ' ', \n",
    "                                       progressbar.Percentage(), \n",
    "                                       \" of {0}\".format(len(class_data))])\n",
    "    bar.start()\n",
    "    for k, class_ in enumerate(class_data):\n",
    "        for i in range(len(n)):\n",
    "            edges_min = edges[i]\n",
    "            edges_max = edges[i+1]\n",
    "            if class_[2] >= edges_min and class_[2] <= edges_max:\n",
    "                for j in range(int((n_max/n[i]))):\n",
    "                    data.append(class_)\n",
    "                break\n",
    "        bar.update(k+1)\n",
    "    bar.finish()\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    accuracy = history.history['mape']\n",
    "    val_accuracy = history.history['val_mape']\n",
    "\n",
    "\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    l1 = ax1.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    vl1 = ax1.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    ax1.set_title('Training and validation loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss (mae))')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ac2= ax2.plot(epochs, accuracy, 'o', c=\"red\", label='Training acc')\n",
    "    vac2= ax2.plot(epochs, val_accuracy, 'r', label='Validation acc')\n",
    "    ax2.set_ylabel('mape')\n",
    "\n",
    "    lns = l1 + vl1 + ac2 + vac2\n",
    "    labs = [l.get_label() for l in lns]\n",
    "    ax2.legend(lns, labs, loc=\"center right\")\n",
    "    fig.tight_layout()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our beautiful probability distributions (non balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BH_tcs = loaddata(\"data_betheheitler/data/{}.csv\".format('BH_tcs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BH_tcs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.]\n",
      " [  1.]\n",
      " [  1.]\n",
      " ...\n",
      " [100.]\n",
      " [100.]\n",
      " [100.]]\n"
     ]
    }
   ],
   "source": [
    "print(BH_tcs[:,0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample of: 8500 \n",
      "Valuation sample: 1500\n"
     ]
    }
   ],
   "source": [
    "x0_train, y0_train, x0_val, y0_val = prepare_data(BH_tcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02954367, 0.05492832, 0.21231345, ..., 0.0020226 , 0.00373216,\n",
       "       0.14915989])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y0_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0.000, 1., 500)\n",
    "plot_histo(x0_train,y0_train,bins,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8500, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Build\n",
    "\n",
    "__1)__ This is the first step in our chaing of Transfer Learning. We have to buil the model that we're going to reuse also in the next trainings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() :\n",
    "    model = models.Sequential()\n",
    "    model.add (BatchNormalization(input_dim = 2))\n",
    "    model.add (layers.Dense (2 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (2 , activation = \"relu\"))\n",
    "    model.add (layers.Dense (1 , activation = \"sigmoid\"))\n",
    "    model.compile(optimizer = \"adam\" , loss = 'mape' , metrics = [\"binary_crossentropy\",\"mae\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-14 11:15:18.763455: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-14 11:15:18.976603: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "266/266 [==============================] - 12s 3ms/step - loss: 21346.1137 - binary_crossentropy: 0.6831 - mae: 0.3418 - val_loss: 28778.6328 - val_binary_crossentropy: 0.6363 - val_mae: 0.3110\n",
      "Epoch 2/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 21536.8835 - binary_crossentropy: 0.6071 - mae: 0.2921 - val_loss: 18728.1191 - val_binary_crossentropy: 0.5108 - val_mae: 0.2170\n",
      "Epoch 3/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 11751.3124 - binary_crossentropy: 0.4944 - mae: 0.1989 - val_loss: 12484.7295 - val_binary_crossentropy: 0.4429 - val_mae: 0.1518\n",
      "Epoch 4/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 10169.2790 - binary_crossentropy: 0.4436 - mae: 0.1445 - val_loss: 8479.8877 - val_binary_crossentropy: 0.4245 - val_mae: 0.1233\n",
      "Epoch 5/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 5961.9964 - binary_crossentropy: 0.4405 - mae: 0.1283 - val_loss: 5839.0752 - val_binary_crossentropy: 0.4338 - val_mae: 0.1159\n",
      "Epoch 6/100\n",
      "266/266 [==============================] - 0s 944us/step - loss: 3878.5406 - binary_crossentropy: 0.4568 - mae: 0.1253 - val_loss: 4102.6392 - val_binary_crossentropy: 0.4578 - val_mae: 0.1184\n",
      "Epoch 7/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 3164.3478 - binary_crossentropy: 0.4591 - mae: 0.1213 - val_loss: 3000.3552 - val_binary_crossentropy: 0.4848 - val_mae: 0.1229\n",
      "Epoch 8/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 2518.0774 - binary_crossentropy: 0.5027 - mae: 0.1293 - val_loss: 2244.6960 - val_binary_crossentropy: 0.5122 - val_mae: 0.1275\n",
      "Epoch 9/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 1564.8814 - binary_crossentropy: 0.5345 - mae: 0.1358 - val_loss: 1734.1548 - val_binary_crossentropy: 0.5353 - val_mae: 0.1310\n",
      "Epoch 10/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 1282.1282 - binary_crossentropy: 0.5501 - mae: 0.1361 - val_loss: 1351.1375 - val_binary_crossentropy: 0.5579 - val_mae: 0.1341\n",
      "Epoch 11/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 959.2588 - binary_crossentropy: 0.5859 - mae: 0.1422 - val_loss: 1072.1932 - val_binary_crossentropy: 0.5689 - val_mae: 0.1352\n",
      "Epoch 12/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 825.7409 - binary_crossentropy: 0.5912 - mae: 0.1419 - val_loss: 866.0324 - val_binary_crossentropy: 0.5677 - val_mae: 0.1344\n",
      "Epoch 13/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 628.2158 - binary_crossentropy: 0.5842 - mae: 0.1396 - val_loss: 709.8638 - val_binary_crossentropy: 0.5564 - val_mae: 0.1319\n",
      "Epoch 14/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 549.5593 - binary_crossentropy: 0.5725 - mae: 0.1375 - val_loss: 589.5362 - val_binary_crossentropy: 0.5362 - val_mae: 0.1277\n",
      "Epoch 15/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 381.4971 - binary_crossentropy: 0.5434 - mae: 0.1312 - val_loss: 492.9125 - val_binary_crossentropy: 0.5289 - val_mae: 0.1257\n",
      "Epoch 16/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 355.5121 - binary_crossentropy: 0.5323 - mae: 0.1287 - val_loss: 417.9221 - val_binary_crossentropy: 0.5231 - val_mae: 0.1248\n",
      "Epoch 17/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 270.8483 - binary_crossentropy: 0.5397 - mae: 0.1306 - val_loss: 358.7702 - val_binary_crossentropy: 0.5119 - val_mae: 0.1222\n",
      "Epoch 18/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 267.1476 - binary_crossentropy: 0.5190 - mae: 0.1254 - val_loss: 310.5833 - val_binary_crossentropy: 0.5273 - val_mae: 0.1255\n",
      "Epoch 19/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 246.6338 - binary_crossentropy: 0.5423 - mae: 0.1315 - val_loss: 272.1042 - val_binary_crossentropy: 0.5073 - val_mae: 0.1214\n",
      "Epoch 20/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 211.4298 - binary_crossentropy: 0.5292 - mae: 0.1290 - val_loss: 240.5458 - val_binary_crossentropy: 0.5129 - val_mae: 0.1229\n",
      "Epoch 21/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 183.5913 - binary_crossentropy: 0.5255 - mae: 0.1275 - val_loss: 214.5767 - val_binary_crossentropy: 0.5124 - val_mae: 0.1225\n",
      "Epoch 22/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 165.2239 - binary_crossentropy: 0.5285 - mae: 0.1278 - val_loss: 194.0542 - val_binary_crossentropy: 0.4960 - val_mae: 0.1191\n",
      "Epoch 23/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 154.2205 - binary_crossentropy: 0.5122 - mae: 0.1248 - val_loss: 176.1640 - val_binary_crossentropy: 0.4992 - val_mae: 0.1197\n",
      "Epoch 24/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 146.2535 - binary_crossentropy: 0.5203 - mae: 0.1266 - val_loss: 161.5395 - val_binary_crossentropy: 0.4946 - val_mae: 0.1189\n",
      "Epoch 25/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 127.1153 - binary_crossentropy: 0.4971 - mae: 0.1213 - val_loss: 148.5719 - val_binary_crossentropy: 0.4854 - val_mae: 0.1171\n",
      "Epoch 26/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 119.6034 - binary_crossentropy: 0.4968 - mae: 0.1213 - val_loss: 140.1213 - val_binary_crossentropy: 0.4775 - val_mae: 0.1138\n",
      "Epoch 27/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 118.7858 - binary_crossentropy: 0.4748 - mae: 0.1139 - val_loss: 130.1397 - val_binary_crossentropy: 0.4608 - val_mae: 0.1086\n",
      "Epoch 28/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 114.5656 - binary_crossentropy: 0.4596 - mae: 0.1090 - val_loss: 121.8703 - val_binary_crossentropy: 0.4468 - val_mae: 0.1010\n",
      "Epoch 29/100\n",
      "266/266 [==============================] - 0s 955us/step - loss: 110.4241 - binary_crossentropy: 0.4417 - mae: 0.0991 - val_loss: 115.2678 - val_binary_crossentropy: 0.4352 - val_mae: 0.0967\n",
      "Epoch 30/100\n",
      "266/266 [==============================] - 0s 943us/step - loss: 102.2619 - binary_crossentropy: 0.4466 - mae: 0.1004 - val_loss: 109.1038 - val_binary_crossentropy: 0.4244 - val_mae: 0.0919\n",
      "Epoch 31/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 97.0647 - binary_crossentropy: 0.4190 - mae: 0.0898 - val_loss: 105.2884 - val_binary_crossentropy: 0.4253 - val_mae: 0.0905\n",
      "Epoch 32/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 99.1315 - binary_crossentropy: 0.4374 - mae: 0.0956 - val_loss: 101.5329 - val_binary_crossentropy: 0.4274 - val_mae: 0.0900\n",
      "Epoch 33/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 92.4691 - binary_crossentropy: 0.4263 - mae: 0.0913 - val_loss: 97.1601 - val_binary_crossentropy: 0.4185 - val_mae: 0.0865\n",
      "Epoch 34/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 84.8008 - binary_crossentropy: 0.4225 - mae: 0.0873 - val_loss: 92.2769 - val_binary_crossentropy: 0.4204 - val_mae: 0.0874\n",
      "Epoch 35/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 87.2962 - binary_crossentropy: 0.4281 - mae: 0.0901 - val_loss: 88.8002 - val_binary_crossentropy: 0.4197 - val_mae: 0.0870\n",
      "Epoch 36/100\n",
      "266/266 [==============================] - 0s 970us/step - loss: 82.9454 - binary_crossentropy: 0.4240 - mae: 0.0876 - val_loss: 87.0653 - val_binary_crossentropy: 0.4142 - val_mae: 0.0836\n",
      "Epoch 37/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 78.3102 - binary_crossentropy: 0.4187 - mae: 0.0861 - val_loss: 82.3489 - val_binary_crossentropy: 0.4057 - val_mae: 0.0818\n",
      "Epoch 38/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 75.7012 - binary_crossentropy: 0.4171 - mae: 0.0857 - val_loss: 79.9771 - val_binary_crossentropy: 0.4069 - val_mae: 0.0830\n",
      "Epoch 39/100\n",
      "266/266 [==============================] - 0s 992us/step - loss: 77.2585 - binary_crossentropy: 0.4178 - mae: 0.0862 - val_loss: 77.0889 - val_binary_crossentropy: 0.4079 - val_mae: 0.0851\n",
      "Epoch 40/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 77.0109 - binary_crossentropy: 0.4124 - mae: 0.0848 - val_loss: 74.8878 - val_binary_crossentropy: 0.4032 - val_mae: 0.0830\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266/266 [==============================] - 0s 1ms/step - loss: 74.4970 - binary_crossentropy: 0.4140 - mae: 0.0874 - val_loss: 74.2708 - val_binary_crossentropy: 0.4027 - val_mae: 0.0822\n",
      "Epoch 42/100\n",
      "266/266 [==============================] - 0s 957us/step - loss: 72.7048 - binary_crossentropy: 0.4070 - mae: 0.0851 - val_loss: 74.0608 - val_binary_crossentropy: 0.4035 - val_mae: 0.0817\n",
      "Epoch 43/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 70.9575 - binary_crossentropy: 0.4100 - mae: 0.0855 - val_loss: 74.1458 - val_binary_crossentropy: 0.4116 - val_mae: 0.0855\n",
      "Epoch 44/100\n",
      "266/266 [==============================] - 0s 1000us/step - loss: 74.3276 - binary_crossentropy: 0.4155 - mae: 0.0880 - val_loss: 71.7563 - val_binary_crossentropy: 0.4070 - val_mae: 0.0843\n",
      "Epoch 45/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 72.4339 - binary_crossentropy: 0.4202 - mae: 0.0889 - val_loss: 73.5797 - val_binary_crossentropy: 0.4195 - val_mae: 0.0887\n",
      "Epoch 46/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 72.1509 - binary_crossentropy: 0.4237 - mae: 0.0899 - val_loss: 71.4009 - val_binary_crossentropy: 0.4112 - val_mae: 0.0855\n",
      "Epoch 47/100\n",
      "266/266 [==============================] - 0s 940us/step - loss: 73.4926 - binary_crossentropy: 0.4217 - mae: 0.0888 - val_loss: 71.0116 - val_binary_crossentropy: 0.4147 - val_mae: 0.0871\n",
      "Epoch 48/100\n",
      "266/266 [==============================] - 0s 961us/step - loss: 70.7646 - binary_crossentropy: 0.4195 - mae: 0.0894 - val_loss: 68.8305 - val_binary_crossentropy: 0.4084 - val_mae: 0.0849\n",
      "Epoch 49/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 71.7412 - binary_crossentropy: 0.4182 - mae: 0.0885 - val_loss: 69.1620 - val_binary_crossentropy: 0.4057 - val_mae: 0.0825\n",
      "Epoch 50/100\n",
      "266/266 [==============================] - 0s 976us/step - loss: 70.8521 - binary_crossentropy: 0.4138 - mae: 0.0861 - val_loss: 70.3181 - val_binary_crossentropy: 0.4064 - val_mae: 0.0810\n",
      "Epoch 51/100\n",
      "266/266 [==============================] - 0s 952us/step - loss: 70.7178 - binary_crossentropy: 0.4224 - mae: 0.0894 - val_loss: 69.1689 - val_binary_crossentropy: 0.4147 - val_mae: 0.0867\n",
      "Epoch 52/100\n",
      "266/266 [==============================] - 0s 915us/step - loss: 68.9915 - binary_crossentropy: 0.4169 - mae: 0.0875 - val_loss: 69.5008 - val_binary_crossentropy: 0.4115 - val_mae: 0.0840\n",
      "Epoch 53/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 74.9300 - binary_crossentropy: 0.4302 - mae: 0.0918 - val_loss: 68.0289 - val_binary_crossentropy: 0.4126 - val_mae: 0.0857\n",
      "Epoch 54/100\n",
      "266/266 [==============================] - 0s 931us/step - loss: 72.7613 - binary_crossentropy: 0.4270 - mae: 0.0906 - val_loss: 69.2234 - val_binary_crossentropy: 0.4114 - val_mae: 0.0839\n",
      "Epoch 55/100\n",
      "266/266 [==============================] - 0s 944us/step - loss: 69.5990 - binary_crossentropy: 0.4231 - mae: 0.0895 - val_loss: 69.6600 - val_binary_crossentropy: 0.4125 - val_mae: 0.0839\n",
      "Epoch 56/100\n",
      "266/266 [==============================] - 0s 966us/step - loss: 70.3336 - binary_crossentropy: 0.4291 - mae: 0.0924 - val_loss: 68.4856 - val_binary_crossentropy: 0.4092 - val_mae: 0.0837\n",
      "Epoch 57/100\n",
      "266/266 [==============================] - 0s 970us/step - loss: 70.2604 - binary_crossentropy: 0.4290 - mae: 0.0916 - val_loss: 70.6170 - val_binary_crossentropy: 0.4202 - val_mae: 0.0874\n",
      "Epoch 58/100\n",
      "266/266 [==============================] - 0s 953us/step - loss: 70.1285 - binary_crossentropy: 0.4241 - mae: 0.0897 - val_loss: 69.5387 - val_binary_crossentropy: 0.4069 - val_mae: 0.0801\n",
      "Epoch 59/100\n",
      "266/266 [==============================] - 0s 936us/step - loss: 71.3916 - binary_crossentropy: 0.4211 - mae: 0.0887 - val_loss: 68.1483 - val_binary_crossentropy: 0.4087 - val_mae: 0.0831\n",
      "Epoch 60/100\n",
      "266/266 [==============================] - 0s 935us/step - loss: 69.9390 - binary_crossentropy: 0.4254 - mae: 0.0911 - val_loss: 68.1758 - val_binary_crossentropy: 0.4071 - val_mae: 0.0817\n",
      "Epoch 61/100\n",
      "266/266 [==============================] - 0s 906us/step - loss: 71.2091 - binary_crossentropy: 0.4240 - mae: 0.0896 - val_loss: 68.1235 - val_binary_crossentropy: 0.4113 - val_mae: 0.0845\n",
      "Epoch 62/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 71.2310 - binary_crossentropy: 0.4305 - mae: 0.0930 - val_loss: 66.8348 - val_binary_crossentropy: 0.4101 - val_mae: 0.0845\n",
      "Epoch 63/100\n",
      "266/266 [==============================] - 0s 902us/step - loss: 69.1432 - binary_crossentropy: 0.4193 - mae: 0.0884 - val_loss: 69.3419 - val_binary_crossentropy: 0.4171 - val_mae: 0.0860\n",
      "Epoch 64/100\n",
      "266/266 [==============================] - 0s 878us/step - loss: 70.7441 - binary_crossentropy: 0.4273 - mae: 0.0912 - val_loss: 68.1383 - val_binary_crossentropy: 0.4038 - val_mae: 0.0795\n",
      "Epoch 65/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 70.7874 - binary_crossentropy: 0.4286 - mae: 0.0916 - val_loss: 67.4949 - val_binary_crossentropy: 0.4197 - val_mae: 0.0895\n",
      "Epoch 66/100\n",
      "266/266 [==============================] - 0s 963us/step - loss: 70.1189 - binary_crossentropy: 0.4173 - mae: 0.0897 - val_loss: 69.8206 - val_binary_crossentropy: 0.4060 - val_mae: 0.0789\n",
      "Epoch 67/100\n",
      "266/266 [==============================] - 0s 968us/step - loss: 69.6567 - binary_crossentropy: 0.4221 - mae: 0.0887 - val_loss: 68.3381 - val_binary_crossentropy: 0.4037 - val_mae: 0.0791\n",
      "Epoch 68/100\n",
      "266/266 [==============================] - 0s 911us/step - loss: 70.0908 - binary_crossentropy: 0.4281 - mae: 0.0921 - val_loss: 68.2559 - val_binary_crossentropy: 0.4073 - val_mae: 0.0814\n",
      "Epoch 69/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 69.0824 - binary_crossentropy: 0.4256 - mae: 0.0903 - val_loss: 68.8623 - val_binary_crossentropy: 0.4026 - val_mae: 0.0779\n",
      "Epoch 70/100\n",
      "266/266 [==============================] - 0s 952us/step - loss: 70.0552 - binary_crossentropy: 0.4303 - mae: 0.0921 - val_loss: 67.4336 - val_binary_crossentropy: 0.4100 - val_mae: 0.0838\n",
      "Epoch 71/100\n",
      "266/266 [==============================] - 0s 940us/step - loss: 70.8452 - binary_crossentropy: 0.4240 - mae: 0.0916 - val_loss: 67.2185 - val_binary_crossentropy: 0.4067 - val_mae: 0.0815\n",
      "Epoch 72/100\n",
      "266/266 [==============================] - 0s 972us/step - loss: 72.3076 - binary_crossentropy: 0.4245 - mae: 0.0888 - val_loss: 69.1249 - val_binary_crossentropy: 0.4196 - val_mae: 0.0875\n",
      "Epoch 73/100\n",
      "266/266 [==============================] - 0s 904us/step - loss: 70.6898 - binary_crossentropy: 0.4297 - mae: 0.0931 - val_loss: 67.8429 - val_binary_crossentropy: 0.4101 - val_mae: 0.0822\n",
      "Epoch 74/100\n",
      "266/266 [==============================] - 0s 963us/step - loss: 69.9004 - binary_crossentropy: 0.4216 - mae: 0.0884 - val_loss: 68.5103 - val_binary_crossentropy: 0.4113 - val_mae: 0.0825\n",
      "Epoch 75/100\n",
      "266/266 [==============================] - 0s 967us/step - loss: 69.7563 - binary_crossentropy: 0.4167 - mae: 0.0857 - val_loss: 67.7424 - val_binary_crossentropy: 0.4193 - val_mae: 0.0888\n",
      "Epoch 76/100\n",
      "266/266 [==============================] - 0s 968us/step - loss: 70.3728 - binary_crossentropy: 0.4357 - mae: 0.0949 - val_loss: 67.3238 - val_binary_crossentropy: 0.4161 - val_mae: 0.0876\n",
      "Epoch 77/100\n",
      "266/266 [==============================] - 0s 936us/step - loss: 68.9791 - binary_crossentropy: 0.4186 - mae: 0.0897 - val_loss: 66.5300 - val_binary_crossentropy: 0.4046 - val_mae: 0.0817\n",
      "Epoch 78/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 68.5240 - binary_crossentropy: 0.4218 - mae: 0.0893 - val_loss: 67.7067 - val_binary_crossentropy: 0.4199 - val_mae: 0.0901\n",
      "Epoch 79/100\n",
      "266/266 [==============================] - 0s 974us/step - loss: 70.2700 - binary_crossentropy: 0.4256 - mae: 0.0934 - val_loss: 69.6276 - val_binary_crossentropy: 0.4076 - val_mae: 0.0811\n",
      "Epoch 80/100\n",
      "266/266 [==============================] - 0s 944us/step - loss: 70.6205 - binary_crossentropy: 0.4193 - mae: 0.0882 - val_loss: 66.7013 - val_binary_crossentropy: 0.4112 - val_mae: 0.0858\n",
      "Epoch 81/100\n",
      "266/266 [==============================] - 0s 962us/step - loss: 69.3045 - binary_crossentropy: 0.4243 - mae: 0.0905 - val_loss: 67.3331 - val_binary_crossentropy: 0.4173 - val_mae: 0.0895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "266/266 [==============================] - 0s 919us/step - loss: 69.9587 - binary_crossentropy: 0.4219 - mae: 0.0910 - val_loss: 69.5694 - val_binary_crossentropy: 0.4150 - val_mae: 0.0864\n",
      "Epoch 83/100\n",
      "266/266 [==============================] - 0s 992us/step - loss: 69.2134 - binary_crossentropy: 0.4236 - mae: 0.0901 - val_loss: 68.0770 - val_binary_crossentropy: 0.4159 - val_mae: 0.0890\n",
      "Epoch 84/100\n",
      "266/266 [==============================] - 0s 917us/step - loss: 70.6865 - binary_crossentropy: 0.4169 - mae: 0.0896 - val_loss: 68.3463 - val_binary_crossentropy: 0.4133 - val_mae: 0.0874\n",
      "Epoch 85/100\n",
      "266/266 [==============================] - 0s 943us/step - loss: 69.0089 - binary_crossentropy: 0.4172 - mae: 0.0888 - val_loss: 67.8695 - val_binary_crossentropy: 0.4172 - val_mae: 0.0900\n",
      "Epoch 86/100\n",
      "266/266 [==============================] - 0s 938us/step - loss: 68.4004 - binary_crossentropy: 0.4220 - mae: 0.0911 - val_loss: 67.9284 - val_binary_crossentropy: 0.3973 - val_mae: 0.0780\n",
      "Epoch 87/100\n",
      "266/266 [==============================] - 0s 948us/step - loss: 69.9925 - binary_crossentropy: 0.4188 - mae: 0.0895 - val_loss: 67.3902 - val_binary_crossentropy: 0.4046 - val_mae: 0.0830\n",
      "Epoch 88/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 68.5263 - binary_crossentropy: 0.4266 - mae: 0.0922 - val_loss: 67.8683 - val_binary_crossentropy: 0.4033 - val_mae: 0.0818\n",
      "Epoch 89/100\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 68.7059 - binary_crossentropy: 0.4219 - mae: 0.0921 - val_loss: 67.2208 - val_binary_crossentropy: 0.4051 - val_mae: 0.0834\n",
      "Epoch 90/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 68.2448 - binary_crossentropy: 0.4204 - mae: 0.0901 - val_loss: 67.2491 - val_binary_crossentropy: 0.3976 - val_mae: 0.0793\n",
      "Epoch 91/100\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 70.2720 - binary_crossentropy: 0.4143 - mae: 0.0896 - val_loss: 66.8618 - val_binary_crossentropy: 0.4021 - val_mae: 0.0828\n",
      "Epoch 92/100\n",
      "266/266 [==============================] - 0s 2ms/step - loss: 68.0517 - binary_crossentropy: 0.4219 - mae: 0.0911 - val_loss: 66.1677 - val_binary_crossentropy: 0.4086 - val_mae: 0.0881\n",
      "Epoch 93/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 68.6668 - binary_crossentropy: 0.4134 - mae: 0.0900 - val_loss: 67.2884 - val_binary_crossentropy: 0.4008 - val_mae: 0.0827\n",
      "Epoch 94/100\n",
      "266/266 [==============================] - 0s 995us/step - loss: 70.3922 - binary_crossentropy: 0.4119 - mae: 0.0882 - val_loss: 66.8114 - val_binary_crossentropy: 0.4066 - val_mae: 0.0875\n",
      "Epoch 95/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 70.4688 - binary_crossentropy: 0.4081 - mae: 0.0879 - val_loss: 67.6496 - val_binary_crossentropy: 0.3939 - val_mae: 0.0801\n",
      "Epoch 96/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 67.6339 - binary_crossentropy: 0.4082 - mae: 0.0865 - val_loss: 67.1417 - val_binary_crossentropy: 0.4136 - val_mae: 0.0924\n",
      "Epoch 97/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 68.3125 - binary_crossentropy: 0.4159 - mae: 0.0912 - val_loss: 68.0120 - val_binary_crossentropy: 0.3975 - val_mae: 0.0834\n",
      "Epoch 98/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 68.2340 - binary_crossentropy: 0.4042 - mae: 0.0862 - val_loss: 66.6654 - val_binary_crossentropy: 0.3902 - val_mae: 0.0801\n",
      "Epoch 99/100\n",
      "266/266 [==============================] - 0s 1ms/step - loss: 67.5418 - binary_crossentropy: 0.4067 - mae: 0.0865 - val_loss: 66.8537 - val_binary_crossentropy: 0.3950 - val_mae: 0.0832\n",
      "Epoch 100/100\n",
      "266/266 [==============================] - 0s 905us/step - loss: 70.1606 - binary_crossentropy: 0.4059 - mae: 0.0871 - val_loss: 67.0104 - val_binary_crossentropy: 0.3937 - val_mae: 0.0824\n"
     ]
    }
   ],
   "source": [
    "model = build_model ()\n",
    "history0 = model.fit ( x0_train, y0_train, epochs = 100, batch_size = 32 , validation_data = (x0_val, y0_val) )\n",
    "model.save(\"models/{}.h5\".format('BH_tcs_pred'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 23\n",
      "Trainable params: 19\n",
      "Non-trainable params: 4\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability density distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred0 = model.predict(x0_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "y0_val = np.array(y0_val)\n",
    "bins = np.linspace(0., 1., 100)\n",
    "pyplot.hist(y0_train, bins, color = 'indianred', alpha=0.5, label='Osiris')\n",
    "pyplot.hist(y_pred0, bins, color = 'mediumslateblue', alpha=0.5, label='NN')\n",
    "pyplot.yscale('log')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.xlabel('Probability')\n",
    "pyplot.title('Trained on ($p_e$, $p_{\\gamma}$)')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
